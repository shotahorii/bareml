{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.knn as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = knn.KNNClassifier(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scripts.knn.KNNClassifier at 0x7f85dbbddd90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,3])\n",
    "\n",
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(a - b, 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-51a2dda32834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "[1,2,3] - [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test!!\n"
     ]
    }
   ],
   "source": [
    "test_mod.test_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "\n",
    "- This notebook doesn't consider include CHAID as it's quite different from others. For CHAID, see [here](http://mephisto.unige.ch/pub/publications/gr/Ritschard-chaid-edm.pdf).\n",
    "- This notebook implements only binary trees not n-ary trees, for [practical reasons](https://sebastianraschka.com/faq/docs/decision-tree-binary.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = pd.get_dummies(iris.target).values # one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Steps\n",
    "\n",
    "1. ノードの分割の候補を洗い出す。  \n",
    "1.1. 全ての特徴量についてループ  \n",
    "1.2. 選択された特徴量について、入力データにおける全ての(現実的に実行可能な)分割閾を候補とする  \n",
    "2. 洗い出した分割候補の中で、最良のものを見つける。  \n",
    "2.1. 上で洗い出した全ての分割に関して、何らかの評価値を計算する。  \n",
    "2.2. 全ての分割の中で最も良い評価値を持つ分割(特徴量x分割閾)でノードを分割する。  \n",
    "3. ccc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisions to make in algorithm design\n",
    "\n",
    "#### Step 1.1.\n",
    "N/A\n",
    "\n",
    "#### Step 1.2. \n",
    "Search space for the best split needs to be defined. For example, there's infinite ways to split an interval \\[0,1\\] if no limitation. Some decisions to make are below.\n",
    "\n",
    "**Number of partitions**  \n",
    "Number of partitions are theoretically not limited to a binary split. Multiple partitions are possible. However, including more numbers of partitions in the search space requires more computation.  \n",
    "For **Nominal scale categorical variables**, the number of possible splits when we consider up to $K$ partitions is given as below.\n",
    "\n",
    "*num_possible_splits* $= \\sum_{k=2}^K S(N,k)$ \n",
    "\n",
    "Where, $S(\\cdot)$ is the *Stirling number of the second kind*. $N$ is the number of distinct nominal values in the variable.\n",
    "\n",
    "For **Ordinal scale categorical variables**, the number of possible splits when we consider up to $K$ partitions is given as below. \n",
    "\n",
    "*num_possible_splits* $= _{N-1}C_{K-1}$\n",
    "\n",
    "Where, $N$ is the number of distinct ordinal values in the variable.\n",
    "\n",
    "For **Continuous variables**, the number of possible splits is *infinity* regardless of the number of partitions to consider. \n",
    "\n",
    "\n",
    "Note: In this notebook I only consider split into 2 (=binary tree). \n",
    " \n",
    "**(For continuous variables) Thresholds, where to split the data**  \n",
    "Though there's infinite way to split the data, if the variable is continuous, there's a common way to define the search space. \n",
    "\n",
    "*Sort the values in the input data, and treat them as values of an ordinal variable (only for the purpose of deciding partitions).*\n",
    "\n",
    "This makes us limit the search space for $K$ partitions split as below.\n",
    "\n",
    "*num_possible_splits* $= _{N-1}C_{K-1}$\n",
    "\n",
    "Where, $N$ is the number of distinct values in the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1. \n",
    "There're multiple metrics can be used for the evaluation. Below are some common ones. \n",
    "\n",
    "#### Gini impurity \n",
    "\n",
    "Given a node $t$, let the number of samples in the node be $n$ and the number of classses in the node be $c$.  \n",
    "When there's $n_i$ samples belonging to the class $i$ in the node $t$, the ratio of samples belonging to $i$ in the node $t$ is expressed as below.\n",
    "\n",
    "$p(i|t) = \\frac{n_i}{n}$\n",
    "\n",
    "Now, Gini impurity is calculated as below.\n",
    "\n",
    "$I_G(t) = 1 - \\sum_i^c p(i|t)^2$\n",
    "\n",
    "#### Entropy\n",
    "\n",
    "With the same setting above, Entropy is calcuated as below.\n",
    "\n",
    "$I_H(t) = -\\sum_i^c p(i|t)log(p(i|t))$\n",
    "\n",
    "#### Information Gain \n",
    "\n",
    "#### Information Gain Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume y is stored as below data format (example of 3 classes with 6 samples)\n",
    "y = np.array([[1,0,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,0,1],\n",
    "              [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y):\n",
    "    # y must not be an empty array\n",
    "    n_each_class = y.sum(axis=0)\n",
    "    n_total = y.shape[0]\n",
    "    p_each_class = n_each_class/n_total\n",
    "    \n",
    "    gini_score = 1 - np.sum(p_each_class**2)\n",
    "    return gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    # y must not be an empty array\n",
    "    n_each_class = y.sum(axis=0)\n",
    "    n_total = y.shape[0]\n",
    "    p_each_class = n_each_class/n_total\n",
    "    \n",
    "    i_each_class = [p*np.log(p) for p in p_each_class if p != 0.0]\n",
    "    return -np.sum(i_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y):\n",
    "    # this one usually not used to grow tree, but used in pruning\n",
    "    # y must not be an empty array\n",
    "    n_max_class = np.max(y.sum(axis=0))\n",
    "    n_total = y.shape[0]\n",
    "    return 1.0 - n_max_class/n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini\n",
      "0.6666666666666667\n",
      "0.6938775510204083\n",
      "0.0\n",
      "0.0\n",
      "Entropy\n",
      "1.0986122886681096\n",
      "1.277034259466139\n",
      "-0.0\n",
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "y1 = np.array([[1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,0,1]])\n",
    "\n",
    "y2 = np.array([[1,0,0,0,0],\n",
    "               [1,0,0,0,0],\n",
    "               [0,1,0,0,0],\n",
    "               [0,0,1,0,0],\n",
    "               [0,0,0,1,0],\n",
    "               [0,0,0,1,0],\n",
    "               [0,0,0,1,0]])\n",
    "\n",
    "y3 = np.array([[1,0,0],\n",
    "               [1,0,0],\n",
    "               [1,0,0]])\n",
    "\n",
    "y4 = np.array([[1,0,0]])\n",
    "\n",
    "print('Gini')\n",
    "print(gini(y1))\n",
    "print(gini(y2))\n",
    "print(gini(y3))\n",
    "print(gini(y4))\n",
    "print('Entropy')\n",
    "print(entropy(y1))\n",
    "print(entropy(y2))\n",
    "print(entropy(y3))\n",
    "print(entropy(y4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 metric='entropy', \n",
    "                 max_depth=None, \n",
    "                 min_impurity_decrease=None, \n",
    "                 is_regression=False, \n",
    "                 train_data_size=None,\n",
    "                 depth=1):\n",
    "        \n",
    "        # parameters to define the behaviour of the entire tree (common across all nodes in the tree)\n",
    "        self.is_regression = is_regression\n",
    "        self.max_depth = max_depth\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.train_data_size = train_data_size\n",
    "        self.metric = metric\n",
    "        \n",
    "        if metric == 'gini':\n",
    "            self.metric_func = self._gini\n",
    "        elif metric == 'entropy':\n",
    "            self.metric_func = self._entropy\n",
    "        else:\n",
    "            raise ValueError('metric parameter needs to be either \"gini\" or \"entropy\".')\n",
    "        \n",
    "        # parameters for each node\n",
    "        self.depth = depth\n",
    "        self.impurity = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "        # parameters about node split\n",
    "        self.impurity_decrease = None\n",
    "        self.split_feature_idx = None\n",
    "        self.split_threshold = None\n",
    "        \n",
    "        # a parameter for leaf nodes\n",
    "        self.predictor = None\n",
    "        \n",
    "        \n",
    "    def _create_node(self):\n",
    "        \"\"\"\n",
    "        Create a node with +1 depth.\n",
    "        \"\"\"\n",
    "        return DecisionTree(metric=self.metric, \n",
    "                            max_depth=self.max_depth, \n",
    "                            min_impurity_decrease=self.min_impurity_decrease, \n",
    "                            is_regression=self.is_regression,\n",
    "                            train_data_size=self.train_data_size,\n",
    "                            depth=self.depth+1)\n",
    "    \n",
    "    def _gini(self, y):\n",
    "        # y must not be an empty array\n",
    "        n_each_class = y.sum(axis=0)\n",
    "        n_total = y.shape[0]\n",
    "        p_each_class = n_each_class/n_total\n",
    "\n",
    "        gini_score = 1 - np.sum(p_each_class**2)\n",
    "        return gini_score\n",
    "    \n",
    "    def _entropy(self, y):\n",
    "        # y must not be an empty array\n",
    "        n_each_class = y.sum(axis=0)\n",
    "        n_total = y.shape[0]\n",
    "        p_each_class = n_each_class/n_total\n",
    "\n",
    "        i_each_class = [p*np.log(p) for p in p_each_class if p != 0.0]\n",
    "        return -np.sum(i_each_class)\n",
    "    \n",
    "    \n",
    "    def _information_gain(self, y_left, y_right):\n",
    "        \"\"\"\n",
    "        Calculate information gain when the data splits into y_left and y_right.\n",
    "        This function refers self.metric and self.impurity.\n",
    "        \n",
    "        Parameters\n",
    "        -------\n",
    "        y_left : np.ndarray\n",
    "            list of y values which go to the left node by the split\n",
    "            \n",
    "        y_right : np.ndarray\n",
    "             list of y values which go to the right node by the split\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gain : float\n",
    "            value of the information gain\n",
    "        \"\"\"\n",
    "\n",
    "        w_left = 1.0*len(y_left)/(len(y_left) + len(y_right))\n",
    "        w_right = 1.0*len(y_right)/(len(y_left) + len(y_right))\n",
    "\n",
    "        if w_left == 0 or w_right == 0:\n",
    "            gain = 0\n",
    "        else:\n",
    "            left_impurity = self.metric_func(y_left)\n",
    "            right_impurity = self.metric_func(y_right)\n",
    "            gain = self.impurity - (left_impurity*w_left + right_impurity*w_right)\n",
    "        \n",
    "        return gain\n",
    "        \n",
    "    \n",
    "    def _find_best_split_threshold(self, x_feature, y):\n",
    "        # find the best split threshold value of the given feature\n",
    "        \n",
    "        max_gain = 0\n",
    "        best_threshold = np.inf\n",
    "        \n",
    "        possible_thresholds = set(x_feature)\n",
    "        \n",
    "        for threshold in possible_thresholds:\n",
    "            left_idx = x_feature < threshold\n",
    "            right_idx = np.array([not i for i in left_idx])\n",
    "            gain = self._information_gain(y[left_idx], y[right_idx])\n",
    "            \n",
    "            if gain > max_gain:\n",
    "                max_gain = gain\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        #best_split_rule = lambda x: x < best_threshold\n",
    "        \n",
    "        return max_gain, best_threshold\n",
    "\n",
    "        \n",
    "    def _find_best_split(self, x, y):\n",
    "        \n",
    "        # init \n",
    "        max_gain = 0\n",
    "        best_split_feature_idx = 0\n",
    "        best_split_threshold = np.inf # all goes to the left\n",
    "        \n",
    "        # for each feature\n",
    "        n_features = x.shape[1] # number of features\n",
    "        for feature_idx in range(n_features):\n",
    "            \n",
    "            x_feature = x[:,feature_idx]\n",
    "            gain, threshold = self._find_best_split_threshold(x_feature, y)\n",
    "            \n",
    "            if gain > max_gain:\n",
    "                best_split_feature_idx = feature_idx\n",
    "                best_split_threshold = threshold\n",
    "        \n",
    "        return best_split_feature_idx, best_split_threshold, max_gain\n",
    "            \n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        # if this is a root node, store the size of entire training data set\n",
    "        if self.depth == 1:\n",
    "            self.train_data_size = len(y)\n",
    "        \n",
    "        # calculate this node's impurity \n",
    "        self.impurity = self.metric_func(y)\n",
    "        \n",
    "        # find the best split\n",
    "        best_split_feature_idx, best_split_threshold, max_gain = self._find_best_split(x, y)\n",
    "        \n",
    "        # split the data by using the best split information\n",
    "        left_idx = x[:,best_split_feature_idx] < best_split_threshold\n",
    "        right_idx = np.array([not i for i in left_idx])\n",
    "        \n",
    "        # store the split information\n",
    "        self.split_feature_idx = best_split_feature_idx\n",
    "        self.split_threshold = best_split_threshold\n",
    "        self.impurity_decrease = max_gain * (1.0*len(y)/self.train_data_size)\n",
    "        \n",
    "        # update \n",
    "        if self.max_depth is not None and self.depth >= self.max_depth:\n",
    "            self.predictor = np.mean(y, axis=0)\n",
    "        elif self.min_impurity_decrease is not None and self.impurity_decrease < self.min_impurity_decrease:\n",
    "            self.predictor = np.mean(y, axis=0)\n",
    "        elif left_idx.sum()==0 or right_idx.sum()==0:\n",
    "            self.predictor = np.mean(y, axis=0)\n",
    "        else:\n",
    "            # fit left\n",
    "            self.left = self._create_node()\n",
    "            self.left.fit(x[left_idx], y[left_idx])\n",
    "            # fit right\n",
    "            self.right = self._create_node()\n",
    "            self.right.fit(x[right_idx], y[right_idx])\n",
    "            \n",
    "        return self\n",
    " \n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        if self.left is None or self.right is None: # this is a leaf node\n",
    "            num_y = self.predictor.shape[0] # number of y to predict (= number of classes if it's classification)\n",
    "            num_x = len(x) # number of samples to predict\n",
    "            pred = np.zeros((num_x, num_y)) + self.predictor\n",
    "\n",
    "            if not self.is_regression: # classification\n",
    "                cls_pred = np.zeros((num_x, num_y))\n",
    "                for i_sample, i_class in enumerate(np.argmax(pred,axis=1)):\n",
    "                    cls_pred[i_sample, i_class] = 1.0\n",
    "                pred = cls_pred\n",
    "        \n",
    "        else: # this isn't a leaf node   \n",
    "            x_feature = x[:,self.split_feature_idx]\n",
    "            \n",
    "            left_idx = x_feature < self.split_threshold\n",
    "            right_idx = np.array([not i for i in left_idx])\n",
    "\n",
    "            left_pred = self.left.predict(x[left_idx])\n",
    "            right_pred = self.right.predict(x[right_idx])\n",
    "\n",
    "            num_y = left_pred.shape[1] # number of y to predict (= number of classes if it's classification)\n",
    "            num_x = len(x) # number of samples to predict\n",
    "            pred = np.zeros((num_x, num_y))\n",
    "\n",
    "            pred[left_idx] = left_pred\n",
    "            pred[right_idx] = right_pred\n",
    "            \n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = DecisionTree(metric='gini', max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionTree at 0x1238f4a58>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging:\n",
    "    def __init__(self, n_trees=5, bootstrap_ratio=1.0, tree=DecisionTree, tree_params={}):\n",
    "        self.n_trees = n_trees\n",
    "        self.bootstrap_ratio = bootstrap_ratio\n",
    "        self.tree = tree\n",
    "        self.tree_params = tree_params\n",
    "        self.trees = []\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        n_samples = int(round(len(x)*self.bootstrap_ratio))\n",
    "        for i in range(self.n_trees):\n",
    "            bootstrap_idx = random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'b':1, 'a':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tes(a,b):\n",
    "    return a*100+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes(**test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'random' has no attribute 'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-455727f03888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'random' has no attribute 'choices'"
     ]
    }
   ],
   "source": [
    "random.choices(np.arange(10), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):\n",
    "    \"\"\" \n",
    "    Calculate euclidean distance (l2 distance) between two vectors \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    v1, v2: np.array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    if len(v1) != len(v2):\n",
    "        raise ValueError(\"2 vectors must have same dimension\")\n",
    "\n",
    "    return math.sqrt(np.power(v1 - v2, 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([[1,5,2],\n",
    "              [3,1,3],\n",
    "              [4,2,0],\n",
    "              [9,1,0],\n",
    "              [0,0,1],\n",
    "              [0,0,1]])\n",
    "\n",
    "y = np.array([[1,0,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,0,1],\n",
    "              [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array([3,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_indices = np.argsort([euclidean_distance(x_pred, x) for x in x1])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_y = y[k_nearest_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_each_class = k_nearest_y.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_each_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class_idx = np.argmax(num_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([3,2],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros([3,2],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[1,0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [3, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "1 20\n",
      "2 30\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate([10,20,30]):\n",
    "    print(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2]),)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(num_each_class==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(x1[1],x2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.58257569495584, 0.0, 3.3166247903554, 6.708203932499369, 3.7416573867739413, 3.7416573867739413]\n",
      "[8.94427190999916, 6.082762530298219, 5.477225575051661, 2.0, 9.1104335791443, 9.1104335791443]\n"
     ]
    }
   ],
   "source": [
    "for x_sample in x2:\n",
    "    print([euclidean_distance(x_sample, x) for x in x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 4 5 0 3]\n",
      "[3 2 1 0 4 5]\n"
     ]
    }
   ],
   "source": [
    "for x_sample in x2:\n",
    "    np.argsort([euclidean_distance(x_sample, x) for x in x1])[:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort([4.58257569495584, 0.0, 3.3166247903554, 6.708203932499369, 3.7416573867739413, 3.7416573867739413])[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.y[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation for leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroRule:\n",
    "    \n",
    "    def __init__(self, is_regression=False):\n",
    "        self.r = None\n",
    "        self.is_regression = is_regression\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.r = np.mean(y, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        num_y = self.r.shape[0] # number of y to predict (= number of classes if it's classification)\n",
    "        num_x = len(x) # number of samples to predict\n",
    "        pred = np.zeros((num_x, num_y)) + self.r\n",
    "        \n",
    "        if self.is_regression:\n",
    "            # regression\n",
    "            return pred\n",
    "        else:\n",
    "            # classification\n",
    "            cls_pred = np.zeros((num_x, num_y))\n",
    "            for i_sample, i_class in enumerate(np.argmax(pred,axis=1)):\n",
    "                cls_pred[i_sample, i_class] = 1.0\n",
    "            return cls_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 depth decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    \n",
    "    def __init__(self, metric, leaf):\n",
    "        self.metric = metric\n",
    "        self.leaf = leaf\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feat_index = 0\n",
    "        self.feat_val = np.nan\n",
    "        self.score = np.nan\n",
    "        \n",
    "    def make_split(self, feature, threshold):\n",
    "        left_ind = feature < threshold\n",
    "        right_ind = feature >= threshold\n",
    "        return left_ind, right_ind\n",
    "    \n",
    "    def make_loss(self, y1, y2):\n",
    "        n_y1, n_y2 = y1.shape[0], y2.shape[0]\n",
    "        \n",
    "        if n_y1 == 0 or n_y2 == 0:\n",
    "            return np.inf\n",
    "        else:\n",
    "            n_total = n_y1 + n_y2\n",
    "            score1 = self.metric(y1)*(n_y1/n_total)\n",
    "            score2 = self.metric(y2)*(n_y2/n_total)\n",
    "            return score1 + score2\n",
    "        \n",
    "    def split_tree(self, x, y):\n",
    "        n_samples = x.shape[0]\n",
    "        n_features = x.shape[1]\n",
    "        self.feat_index = 0\n",
    "        self.feat_val = np.inf\n",
    "        min_loss = np.inf\n",
    "        \n",
    "        left = np.ones(n_samples, dtype=bool) # all true\n",
    "        right = np.zeros(n_samples, dtype=bool) # all false\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            feat = x[:,i]\n",
    "            \n",
    "            for val in feat:\n",
    "                left_ind, right_ind = self.make_split(feat, val)\n",
    "                loss = self.make_loss(y[left_ind], y[right_ind])\n",
    "                \n",
    "                if min_loss > loss:\n",
    "                    min_loss = loss\n",
    "                    left = left_ind\n",
    "                    right = right_ind\n",
    "                    self.feat_index = i\n",
    "                    self.feat_val = val\n",
    "        \n",
    "        self.score = min_loss\n",
    "        return left, right\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.left = self.leaf()\n",
    "        self.right = self.leaf()\n",
    "        left_ind, right_ind = self.split_tree(x, y)\n",
    "        if left_ind.sum() > 0:\n",
    "            self.left.fit(x[left_ind], y[left_ind])\n",
    "        if right_ind.sum() > 0:\n",
    "            self.right.fit(x[right_ind], y[right_ind])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \n",
    "        feat = x[:,self.feat_index]\n",
    "        val = self.feat_val\n",
    "        left_ind, right_ind = self.make_split(feat, val)\n",
    "        \n",
    "        left_pred = self.left.predict(x[left_ind])\n",
    "        right_pred = self.right.predict(x[right_ind])\n",
    "        \n",
    "        num_y = left_pred.shape[1] # number of y to predict (= number of classes if it's classification)\n",
    "        num_x = len(x) # number of samples to predict\n",
    "        pred = np.zeros((num_x, num_y))\n",
    "        \n",
    "        pred[left_ind] = left_pred\n",
    "        pred[right_ind] = right_pred\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N depth Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(DecisionStump):\n",
    "    \n",
    "    def __init__(self, metric, leaf, max_depth, min_impurity_decrease=None, depth=1):\n",
    "        super().__init__(metric=metric, leaf=leaf)\n",
    "        self.max_depth = max_depth\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.depth = depth\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        # perform split\n",
    "        left_ind, right_ind = self.split_tree(x, y)\n",
    "        \n",
    "        # set leaf node as default\n",
    "        self.left = self.leaf()\n",
    "        self.right = self.leaf()\n",
    "        \n",
    "        # replace leaf node with DecisionTree class node, if not max depth\n",
    "        if self.depth < self.max_depth:\n",
    "            if left_ind.sum() > 1:\n",
    "                self.left = self.get_node()\n",
    "            if right_ind.sum() > 1:\n",
    "                self.right = self.get_node()\n",
    "                \n",
    "        # fit the children nodes\n",
    "        if left_ind.sum() > 0:\n",
    "            self.left.fit(x[left_ind], y[left_ind])\n",
    "        if right_ind.sum() > 0:\n",
    "            self.right.fit(x[right_ind], y[right_ind])\n",
    "        return self\n",
    "    \n",
    "    def get_node(self):\n",
    "        return DecisionTree(metric=self.metric, leaf=self.leaf, max_depth=self.max_depth, depth = self.depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducederror(node, x, y):\n",
    "    if isinstance(node, PrunedTree): # node is not a leaf\n",
    "        \n",
    "        # firstly, check if data in x go to both left and right\n",
    "        feat = x[:,node.feat_index]\n",
    "        threshold = node.feat_val\n",
    "        left_ind, right_ind = node.make_split(feat, threshold)\n",
    "        if right_ind.sum() == 0:\n",
    "            return reducederror(node.left, x, y)\n",
    "        elif left_ind.sum() == 0:\n",
    "            return reducederror(node.right, x, y)\n",
    "        \n",
    "        # then, update left and right node\n",
    "        node.left = reducederror(node.left, x[left_ind], y[left_ind])\n",
    "        node.right = reducederror(node.right, x[right_ind], y[right_ind])\n",
    "        \n",
    "        # finally, check if prediction of left or right child node is as good as this prediction\n",
    "        pred = node.predict(x)\n",
    "        pred_l = node.left.predict(x)\n",
    "        pred_r = node.right.predict(x)\n",
    "        \n",
    "        if y.shape[1]>1: # this means this is a classification problem\n",
    "            error = np.sum(abs(pred - y))/2 # number of wrong classification\n",
    "            error_l = np.sum(abs(pred_l - y))/2\n",
    "            error_r = np.sum(abs(pred_r - y))/2\n",
    "        else: # regression\n",
    "            error = np.mean((pred - y)**2) # mean square error\n",
    "            error_l = np.mean((pred_l - y)**2)\n",
    "            error_r = np.mean((pred_r - y)**2)\n",
    "            \n",
    "        if error_l <= error or error_r <= error: # if one or both of children node has smaller error\n",
    "            return node.left if error_l < error_r else node.right # return the smaller error child\n",
    "            \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(node, score):\n",
    "    if isinstance(node, PrunedTree):\n",
    "        if node.score is not np.inf:\n",
    "            score.append(node.score)\n",
    "        get_score(node.left, score)\n",
    "        get_score(node.right, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criticalscore(node, score_max):\n",
    "    if isinstance(node, PrunedTree):\n",
    "        node.left = criticalscore(node.left, score_max)\n",
    "        node.right = criticalscore(node.right, score_max)\n",
    "        \n",
    "        if node.score > score_max:\n",
    "            is_left_leaf = not isinstance(node.left, PrunedTree)\n",
    "            is_right_leaf = not isinstance(node.right, PrunedTree)\n",
    "            if is_left_leaf and is_right_leaf:\n",
    "                return node.left\n",
    "            elif is_left_leaf:\n",
    "                return node.right\n",
    "            elif is_right_leaf:\n",
    "                return node.left\n",
    "            elif node.left.score < node.right.score:\n",
    "                return node.left\n",
    "            else:\n",
    "                return node.right\n",
    "            \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrunedTree(DecisionTree):\n",
    "    def __init__(self, prunfnc='critical', pruntest = False, splitratio=0.5, critical=0.8, \n",
    "                 max_depth=5, metric=gini, leaf=ZeroRule, depth=1):\n",
    "        super().__init__(max_depth=max_depth, metric=metric, leaf=leaf, depth=depth)\n",
    "        self.prunfnc = prunfnc\n",
    "        self.pruntest = pruntest\n",
    "        self.splitratio = splitratio\n",
    "        self.critical = critical\n",
    "    \n",
    "    def get_node(self):\n",
    "        return PrunedTree(prunfnc=self.prunfnc, max_depth=self.max_depth, metric=self.metric, \n",
    "                          leaf=self.leaf, depth=self.depth+1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        # define train data set and test (for puruning) data set\n",
    "        if self.depth == 1 and self.prunfnc is not None:\n",
    "            x_t, y_t = x, y\n",
    "            if self.pruntest:\n",
    "                n_test = int(round(len(x)*self.splitratio))\n",
    "                shuffled_ind = np.random.permutation(len(x))\n",
    "                test_ind = shuffled_ind[:n_test]\n",
    "                train_ind = shuffled_ind[n_test:]\n",
    "                \n",
    "                x_t = x[test_ind]\n",
    "                y_t = y[test_ind]\n",
    "                x = x[train_ind]\n",
    "                y = y[train_ind]\n",
    "        \n",
    "        # perform split\n",
    "        left_ind, right_ind = self.split_tree(x, y)\n",
    "        \n",
    "        # set leaf node as default\n",
    "        self.left = self.leaf()\n",
    "        self.right = self.leaf()\n",
    "        \n",
    "        # replace leaf node with DecisionTree class node, if not max depth\n",
    "        if self.depth < self.max_depth:\n",
    "            if left_ind.sum() > 1:\n",
    "                self.left = self.get_node()\n",
    "            if right_ind.sum() > 1:\n",
    "                self.right = self.get_node()\n",
    "                \n",
    "        # fit the children nodes\n",
    "        # this if condition means, if depth < max_depth (= children nodes are not leaf), then fit the children nodes anyway. \n",
    "        # and if depth == max_depth (= children nodes are leaves), then check prunfunc. If prunfnc is critical, don't fit the leaves yet. \n",
    "        if self.depth < self.max_depth or self.prunfnc != 'critical':\n",
    "            if left_ind.sum() > 0:\n",
    "                self.left.fit(x[left_ind], y[left_ind])\n",
    "            if right_ind.sum() > 0:\n",
    "                self.right.fit(x[right_ind], y[right_ind])\n",
    "           \n",
    "        # execute pruning\n",
    "        if self.depth == 1 and self.prunfnc is not None:\n",
    "            if self.prunfnc == 'reduce':\n",
    "                reducederror(self, x_t, y_t)\n",
    "            elif self.prunfnc == 'critical':\n",
    "                score = []\n",
    "                getscore(self, score)\n",
    "                if len(score) > 0:\n",
    "                    score_max = np.percentile(score, int(round(100*critical)), interpolation='lower')\n",
    "                    criticalscore(self, score_max)\n",
    "                self.fit_leaf(x, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def fit_leaf(self, x, y):\n",
    "        feat = x[:,self.feat_index]\n",
    "        val = self.feat_val\n",
    "        left_ind, right_ind = self.make_split(feat, val)\n",
    "        \n",
    "        if left_ind.sum() > 0:\n",
    "            if isinstance(self.left, PrunedTree):\n",
    "                self.left.fit_leaf(x[left_ind], y[left_ind])\n",
    "            else:\n",
    "                self.left.fit(x[left_ind], y[left_ind])\n",
    "        \n",
    "        if right_ind.sum() > 0:\n",
    "            if isinstance(self.right, PrunedTree):\n",
    "                self.right.fit_leaf(x[right_ind], y[right_ind])\n",
    "            else:\n",
    "                self.right.fit(x[right_ind], y[right_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(len(y)*0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 4, 3, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_rule = lambda x: x < 1\n",
    "split_rule = lambda x: np.array([val in comb for val in x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True,  True])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_rule(y[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,0,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,1,2],\n",
    "              [0,0,1],\n",
    "              [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 2],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,2].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = np.array([x in (1,2) for x in feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(len(tes)*[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False, False, False])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([not i for i in tes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_t+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 3, 3],\n",
       "       [3, 4, 3],\n",
       "       [3, 4, 3],\n",
       "       [3, 4, 3],\n",
       "       [3, 3, 4],\n",
       "       [3, 3, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array([[0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,0,1],\n",
    "              [0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(abs(y - y2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmax(axis=1) == y2.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = DecisionStump(metric = entropy, leaf = ZeroRule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionStump at 0x119990828>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.feat_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS.feat_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b'), ('a', 'c'), ('b', 'c')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "list(combinations(['a','b','c'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array([False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (0,) could not be broadcast to indexing result of shape (0,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-7c66f4af7c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (0,) could not be broadcast to indexing result of shape (0,3)"
     ]
    }
   ],
   "source": [
    "x[[]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 1,  1,  1],\n",
       "       [ 0,  0,  0],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shotahorii/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/ipykernel_launcher.py:1: RuntimeWarning: Mean of empty slice.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/shotahorii/.pyenv/versions/anaconda3-2.5.0/lib/python3.5/site-packages/numpy/core/_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,0,0])+x[[]].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[[1,2]] = np.array([[1,1,1],[0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 1,  1,  1],\n",
       "       [ 0,  0,  0],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([e in [1,2] for e in tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_sample, i_class in enumerate(np.argmax(pred,axis=1)):\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def split_non_nominal(self, feature, threshold):\n",
    "        left_ind = feature < threshold\n",
    "        right_ind = feature >= threshold\n",
    "        return left_ind, right_ind\n",
    "    \n",
    "    def possible_split_non_nominal(self, feature):\n",
    "        return set(feature)\n",
    "    \n",
    "    def possible_split_nominal(self, feature):\n",
    "        possible_values = set(feature)\n",
    "        n_values = len(possible_values)\n",
    "        \n",
    "    \n",
    "    def split_nominal(self, feature, vars_left):\n",
    "        left_ind = np.array([x in vars_left for x in feature])\n",
    "        right_ind = np.array([x not in vars_left for x in feature])\n",
    "        return left_ind, right_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
